# 爬取某小说榜单爬虫及可视化分析

#### 介绍
    GUI登录+爬虫界面+python爬虫+数据清洗与处理+mysql储存数据+pyecharts可视化展示

#### 软件架构
    （1）通过tkinter制作GUI界面，通过按钮触发爬虫事件，数据分析事件。
    
    （2）爬虫提取数据，并通过机器学习算法进行相关的计算求和，以及数据清洗和断句。
    
    （3）点击数据分析按钮自动跳转超链接，html页面中包括热门小说类型统计图，热点分析图（词云图），热门小说状态扇形图，作者字数天梯榜，字数-排名分析散点图



#### 环境说明

    计算机系统版本：Window10
    
    python版本：Python3.7.6
    
    编辑器：PyCharm2019


#### 代码说明
（1）爬虫网站选取

    确定要爬取的网站，通过“F12”查看前端源代码，分析爬取信息的可行性，然后找到需要爬取的标签，内容分别为"序号", "类型", "小说名称", "更新章节", "状态", "字数", "作者", "更新时间"。

（2）爬虫方法getList（）编写

    首先通过etree.HTML获得网站源码，然后通过xpath方法通过途径查找想要爬取的标签文本。然后将它们通过遍历添加到一个数组中，并且返回数组，同时将他们写入bangdan.csv文件当中。

（3）登录+爬虫界面设计

    通过tkinter库设计窗体，依次添加容器和需要的组件,有登录界面和爬虫界面。

（4）数据处理

    通过机器学习算法，例如Pandas库，对文件中的数据进行处理，如求和以及分组等。

（5）数据可视化

    将处理以后的数据通过pyecharts工具生成直观可视的图表，我们可能从中得到我们想要的信息。

（6）实现爬虫日志

    爬虫日志记录爬取事件，使用线程数量，爬取数量，爬取总耗时，日志存取在spider_log.txt中。

（7）实现mysql存储爬取数据

```
 mysql处理截取数据，连接数据库存取
```

 



![输入图片说明](http://r4iex5c0m.hn-bkt.clouddn.com/1.png)

![输入图片说明](http://r4iex5c0m.hn-bkt.clouddn.com/2.png)

![输入图片说明](http://r4iex5c0m.hn-bkt.clouddn.com/3.png)

# 启动方式

1.先用pycharm运行一下login.py,然后按照错误提示安装所缺模块，建议使用pip安装所缺模块。

2.解决错误后，运行login.py即可启动项目。

3.mysql数据库名、用户名、密码要更改为自己的。
